# â”€â”€â”€ INPUTâ€‘STAGE IMPORTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import argparse         # CLI contract
import os               # Filesystem sanity checks
import pandas as pd     # Columnar analytics

# â”€â”€â”€ PROCESSâ€‘STAGE IMPORTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import math             # Deterministic rounding (ceil) if we extend output
import datetime         # Future-proof: timestamp reports & email subjects

# â”€â”€â”€ OUTPUTâ€‘STAGE IMPORTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from rich.console import Console
from rich.table import Table
import smtplib, ssl
from email.mime.text import MIMEText


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. CLI CONTRACT (single responsibility: parse + validate argv)         
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def parse_args() -> argparse.Namespace:
    """
    Build and immediately parse the command-line interface.

    WHY
    ----
    â€¢ Encapsulates all user-facing knobs in one place.  
    â€¢ Keeps `main()` agnostic of `argparse` internals.  
    â€¢ Raises `SystemExit(2)` automatically on misuse, preventing
      downstream functions from ever receiving invalid inputs.

    RETURNS
    -------
    argparse.Namespace with 4 guaranteed attributes:
        file             : str  (path to AWS CUR/CSV) â€“ always exists
        threshold        : float  (% spike trigger)
        email            : Optional[str]
        notify_always    : bool  (True if flag present)
    """
    p = argparse.ArgumentParser(
        prog="aws_cost_sentry",
        description="Lightweight watcher for AWS Cost-and-Usage CSV exports"
    )
    p.add_argument(
        "--file", required=True,
        help="Absolute or relative path to Cost & Usage CSV"
    )
    p.add_argument(
        "--threshold", type=float, default=100.0,
        help="Spike percentage triggering an alert (Î” day-over-day)."
    )
    p.add_argument(
        "--email",
        help="Destination address for SMTP alert (omit â†’ console-only)."
    )
    p.add_argument(
        "--notify-always", action="store_true",
        help="Send eâ€‘mail even when no spike detected."
    )
    return p.parse_args()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. INGEST  â†’  AGGREGATE (pure functions, no sideâ€‘effects)             
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def load_csv(path: str) -> pd.DataFrame:
    """
    Safely load the AWS CUR CSV into memory.

    RULES / ASSUMPTIONS
    -------------------
    â€¢ Path must exist and be readable; otherwise we fail fast.  
    â€¢ Caller handles `FileNotFoundError`.  
    â€¢ Leaves original column names untouched for auditing parity.

    RETURNS
    -------
    DataFrame with *at least* the columns :
        Date, ProductName, UnblendedCost
    """
    if not os.path.exists(path):
        raise FileNotFoundError(path)
    return pd.read_csv(path)


def aggregate(df: pd.DataFrame) -> pd.DataFrame:
    """
    Convert raw line-items into a Date * Service cost matrix.

    WHY
    ----
    â€¢ Matrix is the minimal representation needed for %
      change calculation and tabular display.
    â€¢ By pivoting once, later steps never re-compute aggregates,
      which is important when CSV >100k rows.

    RETURNS
    -------
    DataFrame indexed by Date with one column per ProductName.
    Missing combinations are NaN (interpreted as zero spend).
    """
    daily = (
        df.groupby(["Date", "ProductName"])["UnblendedCost"]
          .sum()
          .reset_index()
    )
    return daily.pivot_table(
        index="Date",
        columns="ProductName",
        values="UnblendedCost",
        aggfunc="sum"
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. DETECT ANOMALIES                                                   
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def detect_spikes(pivot: pd.DataFrame, threshold: float) -> pd.DataFrame:
    """
    Identify services whose day-over-day Î” exceeds the threshold.

    TECHNICAL NOTES
    ---------------
    â€¢ Uses `pct_change()` which preserves NaN for first row.  
    â€¢ Rows with *no* service breaching threshold are dropped to keep
      e-mail concise.  
    â€¢ `.round(1)` keeps output human-readable without losing signal.
    """
    delta = pivot.pct_change() * 100
    return (
        delta[abs(delta) >= threshold]
        .dropna(how="all")
        .round(1)
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. RENDER TO TERMINAL                                                 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
console = Console()

def render_table(pivot: pd.DataFrame, spikes: pd.DataFrame) -> None:
    """
    Pretty-print the daily cost matrix plus a spike banner.

    â€¢ Always prints the full pivot for transparency.  
    â€¢ Emits a red banner only when `spikes` is non-empty.  
    â€¢ Never raises: safe to call in production regardless of data size.
    """
    table = Table(title="AWS Daily Cost (USD)")
    table.add_column("Date", style="cyan", no_wrap=True)
    for svc in pivot.columns:
        table.add_column(svc, justify="right")

    for date, row in pivot.fillna(0).iterrows():
        cells = [date] + [f"{row[c]:.2f}" for c in pivot.columns]
        table.add_row(*cells)

    console.print(table)

    if not spikes.empty:
        console.print(
            f"[bold red]âš   {len(spikes)} spike row(s) detected above threshold[/]"
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. OPTIONAL EMAIL                                                     
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def send_email(body: str, to_addr: str, cfg: dict) -> None:
    """
    Fire a plaintext email via SSL-secured SMTP.

    Parameters
    ----------
    body     : Plaintext payload (already formatted).
    to_addr  : Recipient.
    cfg      : Dict with keys host, port, sender, password.

    Raises
    ------
    smtplib.SMTPException on network/auth failure.
    """
    msg = MIMEText(body, "plain", "utf-8")
    msg["Subject"] = f"AWS Cost Spike {datetime.date.today()} ðŸš¨"
    msg["From"] = cfg["sender"]
    msg["To"] = to_addr

    ctx = ssl.create_default_context()
    with smtplib.SMTP_SSL(cfg["host"], cfg["port"], context=ctx) as s:
        s.login(cfg["sender"], cfg["password"])
        s.sendmail(cfg["sender"], [to_addr], msg.as_string())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. GLUE  (imperative orchestration)                                  
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def main() -> None:
    """
    Orchestrate ETLâ†’detectâ†’render(+optional alert).

    Guarantees
    ----------
    â€¢ Console always receives a report.  
    â€¢ Script exits 0 on success, non-zero on handled error.
    """
    args = parse_args()
    pivot  = aggregate(load_csv(args.file))
    spikes = detect_spikes(pivot, args.threshold)
    render_table(pivot, spikes)

    if args.email and (not spikes.empty or args.notify_always):
        body = spikes.to_string() if not spikes.empty else "No anomalies."
        send_email(body, args.email, {
            "host": "smtp.gmail.com",
            "port": 465,
            "sender": "you@example.com",
            "password": "app-password"
        })

# Kickâ€‘off only when invoked directly, not on import.
if __name__ == "__main__":
    main()
